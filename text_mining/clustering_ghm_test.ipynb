{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de clustering de GHM\n",
    "\n",
    "Utilisation de *sentence_transformers* pour créer des clusters de GHM par similarité sémantique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fa9cc928-5a6b-477b-90ed-5e97c5bb3600",
     "showTitle": true,
     "title": "install sentence transformer required for SBERT"
    },
    "id": "_5o0ynEIsX1Q",
    "outputId": "e285c64e-2eec-45c3-f4e8-c274d27f583e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\trist\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.25.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\trist\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.59.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\trist\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.97)\n",
      "Requirement already satisfied: nltk in c:\\users\\trist\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.11.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\trist\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.12.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\trist\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\trist\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.24.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\trist\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\trist\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: requests in c:\\users\\trist\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.4.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\trist\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\trist\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (8.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\trist\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (4.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2f591624-c01a-4f34-905a-87373fe12742",
     "showTitle": true,
     "title": "import necessary packages"
    },
    "id": "Rj-tHT30sX1U",
    "outputId": "0f57aca7-b026-4053-bda3-e604f6a8e516"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "995ade15-14f7-4307-88fc-9d9aefbb62ae",
     "showTitle": true,
     "title": "Considered pre trained model all-MiniLM-L6-v2"
    },
    "id": "2700tADtsX1V",
    "outputId": "ed5d5c69-7b0a-415f-acb8-2119d67e2f17"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Sentence embeddings model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exemples de codes GHM\n",
    "\n",
    "GHM= [\"28z04z\", \"28z07z\", \"05m092\",\n",
    "      \"02c05j\", \"28z14z\", \"05m093\",\n",
    "      \"28z17z\", \"28z18z\", \"05k101\",\n",
    "      \"05k051\", \"05m042\", \"08c322\"\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['05m042', '08c322', '28z07z', '05m093'],\n",
       " ['28z07z', '28z17z', '28z07z', '05m042', '28z07z', '28z04z'],\n",
       " ['05m042', '05k101', '28z17z', '28z18z', '28z14z', '05m092'],\n",
       " ['28z04z', '05m042', '05m042', '05m042', '08c322', '08c322'],\n",
       " ['28z04z', '05k051', '05k101', '05m093', '05m093', '05m042'],\n",
       " ['28z17z', '08c322', '08c322', '28z17z'],\n",
       " ['05m092', '28z07z', '05m092', '28z18z', '28z14z', '08c322'],\n",
       " ['05k051', '05m093', '05m042', '05m092'],\n",
       " ['05k051', '05m092', '08c322', '05m092', '05m093'],\n",
       " ['02c05j', '05m093', '28z04z', '28z17z']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creation d'une base de données fictives\n",
    "db=[]\n",
    "nb_patients=10\n",
    "\n",
    "for i in range(nb_patients):\n",
    "    db.append(rd.choices(GHM, k=rd.randint(3,6)))\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28z04z',\n",
       " '28z07z',\n",
       " '05m092',\n",
       " '02c05j',\n",
       " '28z14z',\n",
       " '05m093',\n",
       " '28z17z',\n",
       " '28z18z',\n",
       " '05k101',\n",
       " '05k051',\n",
       " '05m042',\n",
       " '08c322']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c29c9e55-4f1d-4887-84e8-9da376b2a900",
     "showTitle": true,
     "title": "Store errors in Python list. SBERT needs text in list format to process"
    },
    "id": "FggDGYoOsX1Y",
    "outputId": "8e1fd02c-3ab9-42e6-8c68-0c4c174ebf66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_sentences=GHM\n",
    "type(corpus_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "969a0055-ab21-4015-aafa-493f08a3d43b",
     "showTitle": true,
     "title": "Encoding the sentences"
    },
    "id": "weBb_8QesX1Z",
    "outputId": "fe39d09f-c6b4-486c-bd13-473be1faf01e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode the corpus. This might take a while\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3794ef77c843427c9114bc793f956f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Encode the corpus. This might take a while\")\n",
    "corpus_embeddings = model.encode(corpus_sentences, batch_size=64, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 384])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = util.community_detection(corpus_embeddings, min_community_size=1,\n",
    "                                    threshold=0.8\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 4, 6, 7], [2, 5, 8, 9, 10], [3], [11]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "784f63ed-a4b5-4ac6-9541-4ba4e1f2b369",
     "showTitle": true,
     "title": "Clustering the encoded text & store the result in pandas dataframe"
    },
    "id": "jt8siNFgsX1Z",
    "outputId": "3c4df655-038a-4575-f678-35d07176003f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0, 1, 4, 6, 7]\n",
      "1 [2, 5, 8, 9, 10]\n",
      "2 [3]\n",
      "3 [11]\n"
     ]
    }
   ],
   "source": [
    "nb_clusters=len(clusters)\n",
    "df_cluster=pd.DataFrame(columns=['Cluster','GHM'])\n",
    "j=0\n",
    "\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(i, cluster)\n",
    "    cluster_len=len(cluster)\n",
    "  \n",
    "    for sentence_id in cluster[0:len(cluster)]:\n",
    "        df_cluster.loc[j,['Cluster']]=i+1\n",
    "        df_cluster.loc[j,['GHM']]=corpus_sentences[sentence_id]\n",
    "        j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 : ['28z04z', '28z07z', '28z14z', '28z17z', '28z18z']\n",
      "Cluster 2 : ['05m092', '05m093', '05k101', '05k051', '05m042']\n",
      "Cluster 3 : ['02c05j']\n",
      "Cluster 4 : ['08c322']\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(clusters)+1):\n",
    "    print(\"Cluster\", i, \":\", df_cluster[df_cluster['Cluster']==i]['GHM'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9220320b-d937-4676-a706-0fbdbf81418a",
     "showTitle": false,
     "title": ""
    },
    "id": "YKHUnn3ksX1a",
    "outputId": "a7ecdc67-0175-438d-a125-b1d322c8fab1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>GHM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28z04z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28z07z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>28z14z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>28z17z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>28z18z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>05m092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>05m093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>05k101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>05k051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>05m042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>02c05j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>08c322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster     GHM\n",
       "0        1  28z04z\n",
       "1        1  28z07z\n",
       "2        1  28z14z\n",
       "3        1  28z17z\n",
       "4        1  28z18z\n",
       "5        2  05m092\n",
       "6        2  05m093\n",
       "7        2  05k101\n",
       "8        2  05k051\n",
       "9        2  05m042\n",
       "10       3  02c05j\n",
       "11       4  08c322"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Error Cluster",
   "notebookOrigID": 2402594287099368,
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
